eta1_pre = eta1_pre,
eta2_pre = eta2_pre,
eta3_pre = eta3_pre,
k = k, X1 = X1, x = x, phi = 1/phi,
G = G, tttt = tttt)$tmp
ll = sum(c(G_ugk * tmp)[is.na(c(G_ugk * tmp)) == FALSE])
return(-(ll))
}
#-----------------------------QMC nodes-----------------------------
qmc.grid = halton(nn, 2 * n_basis+1, init = TRUE, normal = FALSE, usetime = FALSE)
dim(qmc.grid)
eta1_pre = qnorm(qmc.grid[,1])
eta2_pre = t(qnorm(qmc.grid[,2:(n_basis + 1)]))
eta3_pre = t(qnorm(qmc.grid[,(n_basis + 2) : (2 * n_basis + 1)]))
wt = rep(1/nn,nn)
#----------------------------EM algorithm-------------------------
index = NULL
wt = NULL
j = 0
ll0 = 0
ll1 = 100
while (abs(ll0-ll1)/abs(ll0) >= 1e-2){
j = j+1
print(paste0("j_", j))
ll0 = ll1
p_k_pre = p_k
lll1 = likelihood_SP(sigma2, sigma1_2, mu1, p_k, sigma2_2, index, wt, Y1 = Y1,
eta1_pre = eta1_pre,
eta2_pre = eta2_pre,
eta3_pre = eta3_pre,
k = k, X1 = X1, x = x, phi = 1/phi,
G = G, tttt = tttt)
tmp = lll1$tmp
G_ugk = foreach(gg = c(1:G), .combine = "rbind", .export = c("tmp", "k")) %do%{
res = rep(0, k)
if(max(tmp[gg,]) <= -700){
res[which.max(tmp[gg,])] = 1
res[which(tmp[gg, ] == -2000)] = 0
}else{
res = ((exp(tmp[gg,] ))/sum(exp(tmp[gg,])))
}
res
}
p_k = apply(G_ugk, 2, sum)/sum(apply(G_ugk, 2, sum))
par = c(sigma1_2, mu1, sigma2, sigma2_2)
result2 = nlminb(par, likelihood_f_sig1, lower = c(1e-10, -Inf, rep(1e-10, n_basis), rep(1e-10, n_basis)),
upper = rep(20, length(par)), control=list(iter.max = 1, trace=1, step.max = 1/(2^(j-1))))
par = result2$par
sigma1_2 = par[1]
mu1 = par[2]
sigma2 = par[(1:n_basis)+2]
sigma2_2 = par[(1:n_basis) + 2 + n_basis]
bb = proc.time()
ll1 = likelihood_SP(sigma2, sigma1_2, mu1, p_k, sigma2_2, index, wt,
Y1 = Y1,
eta1_pre = eta1_pre,
eta2_pre = eta2_pre,
eta3_pre = eta3_pre,
k = k, X1 = X1, x = x, phi = 1/phi,
G = G, tttt = tttt)$ll
proc.time() - bb
index = list()
wt = list()
if(j == 1){
n_step_pre <- nn
}else{
n_step_pre <- n_step
}
# n_step_pre <- n_step
n_step <- round(n_step_pre/(2^(j-1)))
if(n_step <= 100){
n_step = 100
j = j - 1
}
for (kk in c(1:k)){
stat1 = apply(lll1$res_pre[[kk]], 2, sum)
index[[kk]] = sample(x = c(1:(n_step_pre)), size = n_step, prob = (stat1 - min(stat1) + 1 )/sum((stat1 - min(stat1) + 1)))
wt[[kk]] = (n_step * stat1/sum(stat1))[index[[kk]]]
}
ress = list(mu1 = mu1, sigma1_2 = sigma1_2, sigma2 = sigma2, sigma2_2 = sigma2_2, p_k = p_k)
}
result1 = list(mu1 = mu1, sigma1_2 = sigma1_2, sigma2 = sigma2, sigma2_2 = sigma2_2, p_k = p_k, phi = phi)
return(list(data_use = data_use, result1 = result1))
}
est_result <- estimation_fun(n_control = n_control,
n_treat = n_treat,
n_rep = n_rep,
x = x,
Y1 = Y1,
nn = 300,
k = 4,
phi = NULL,
type = 2)
warnings()
#' @import foreach
#' @import MASS
#' @import mvtnorm
#' @import randtoolbox
#' @import stats
#' @import mclust
#' @import EQL
#' @import matlib
#' @import parallel
#' @md
MAP_test = function(est_result,
dd = NULL,
Type = c(1:6),
nn = 6000){
data_use <- est_result$data_use
result1 <- est_result$result1
n_basis <- data_use$n_basis
# aa <- result1$aa
# aa_use <- aa
# aa_use[which(is.na(log(aa)))] = mean(aa, na.rm = T)
phi <- 1/result1$phi
k <- data_use$k
X1 <- data_use$X1
x <- data_use$x
tttt <- data_use$tttt
G <- dim(data_use$Y1)[1]
Y1 <- data_use$Y1
qmc.grid = halton(nn, 2 * n_basis+1, init = TRUE, normal = FALSE, usetime = FALSE)
eta1_pre = qnorm(qmc.grid[,1])
eta2_pre = t(qnorm(qmc.grid[,2:(n_basis + 1)]))
eta3_pre = t(qnorm(qmc.grid[,(n_basis + 2) : (2 * n_basis + 1)]))
wt = rep(1/nn,nn)
eta2 = x %*% ((eta2_pre ) * sqrt(result1$sigma2))
T_stat_fun = function(sigma2, sigma1_2 , sigma2_2, mu1 , p_k, aa_use){
# phi = rep(1/aa_use, each = n_control + n_treat)
# phi = 1/aa_use
# phi <- 1/1
mm_c_full = list()
for (kk in c(1:k)){
if(kk %in% c(1,2)){
eta1 = rep(0, nn)
}else{
eta1 = eta1_pre * sqrt(sigma1_2) + mu1
}
if(kk %in% c(1,3)){
eta3 = X1 * x %*% (eta3_pre) * 0
}else{
eta3 = X1 * x %*% (eta3_pre * sqrt(sigma2_2))
}
lambda = matrix(0, nrow = nn, ncol = length(tttt))
for(ii in c(1:nn)){
lambda[ii,] = exp(X1 * eta1[ii] + eta2[,ii] + eta3[,ii])
}
f_y_g_eta = function(ii, lambda){
Y = c(t(Y1))
lambda_use = c(replicate(G, lambda[ii,]))
# res = apply(matrix(dnbinom(Y, size = phi, mu = lambda_use, log = T), ncol = G), 2, sum)
res1 = apply(matrix((Y * (log(lambda_use) - log(phi + lambda_use)) +
phi * (log(phi) - log(phi + lambda_use))), ncol = G), 2, sum)
return(res1)
}
res_pre <- foreach(ii = c(1:nn), .combine = "cbind")%do%{
f_y_g_eta(ii, lambda = lambda)
}
res = apply(exp(res_pre), 1, mean)
mm_c_full[[kk]] = res_pre
print(kk)
}
res = matrix(0, nrow = G, ncol = 4)
res_full = matrix(0, nrow = G * length(tttt), ncol = 4)
for(kk in c(1:4)){
res[, kk] = log(apply(exp(mm_c_full[[kk]]), 1, mean)) + log(p_k[kk])
res[res[, kk] == -Inf, kk] = -2000
}
return(res)
}
T_x = T_stat_fun(sigma2 = result1$sigma2,
sigma1_2 = result1$sigma1_2,
sigma2_2 = result1$sigma2_2,
mu1 =  result1$mu1,
p_k = result1$p_k,
aa_use = aa_use)
T_x = (T_x - apply(T_x, 1, max))
FDR_ct = seq(1e-5, 0.6, length.out = 100)
if(is.null(dd)){
FDR <- matrix(0, 100, length(Type))
FDR_final = ct_final_all = matrix(0, length(FDR_ct), length(Type))
test_stat = matrix(0, G, length(Type))
for(ii in c(1:length(Type))){
kk = Type[ii]
print(kk)
if(kk == 1){
index_use = 1 #general DE detection
}else if(kk == 2){
index_use = c(1,2) #mean difference detection
}else if(kk == 3){
index_use = c(1,3) #NPDE detection
}else if(kk == 4){
index_use = c(1,2,4) #PDE with no time-by-treatment
}else if(kk == 5){
index_use = c(1,3,4) # NPDE with only time-by-treatment
}else if(kk == 6){
index_use = c(1,2,3)
}
print(index_use)
res = apply(t(t(exp(T_x)[,index_use])), 1, sum)/apply(exp(T_x), 1, sum)
test_stat[,ii] = res
ct =  seq(min(res),quantile(res)[4], length.out = 100)
for (jj in c(1:length(ct))){
phi_x = (res<=ct[jj])
FDR[jj,ii] = sum(res*phi_x)/sum(phi_x)
}
for(jj in c(1:length(FDR_ct))){
ct_final = max(ct[which(FDR[,ii] == max(FDR[which (FDR[,ii]<=FDR_ct[jj]), ii]))] )
ct_final_all[jj, ii] = ct_final
phi_x = (res<=ct_final)
FDR_final[jj, ii] = sum(res*phi_x)/sum(phi_x)
}
}
result = list(Type = Type,
FDR_final = FDR_final,
T_x = T_x,
test_stat = test_stat,
ct_final_all = ct_final_all)
}else{
FDR = matrix(0, 100, length(Type))
FDR_final = FDR_real = power = ct_final_all = matrix(0, length(FDR_ct), length(Type))
test_stat = matrix(0, G, length(Type))
for(ii in c(1:length(Type))){
kk = Type[ii]
print(kk)
if(kk == 1){
index_use = 1 #general DE detection
}else if(kk == 2){
index_use = c(1,2) #mean difference detection
}else if(kk == 3){
index_use = c(1,3) #NPDE detection
}else if(kk == 4){
index_use = c(1,2,4) #PDE with no time-by-treatment
}else if(kk == 5){
index_use = c(1,3,4) # NPDE with only time-by-treatment
}else if(kk == 6){
index_use = c(1,2,3)
}
print(index_use)
res = apply(t(t(exp(T_x)[,index_use])), 1, sum)/apply(exp(T_x), 1, sum)
test_stat[,ii] = res
ct =  seq(min(res),quantile(res)[4], length.out = 100)
for (jj in c(1:length(ct))){
phi_x = (res<=ct[jj])
FDR[jj,ii] = sum(res*phi_x)/sum(phi_x)
}
for(jj in c(1:length(FDR_ct))){
ct_final = max(ct[which(FDR[,ii] == max(FDR[which (FDR[,ii]<FDR_ct[jj]), kk]))] )
ct_final_all[jj, ii] = ct_final
phi_x = (res<ct_final)
FDR_final[jj, ii] = sum(res*phi_x)/sum(phi_x)
FDR_real[jj, ii] = sum(phi_x[which(dd %in% c(index_use-1))])/sum(phi_x)
power[jj, ii] = sum(phi_x[which(dd %in% c(0:(k-1))[-index_use])])/sum(dd %in%  c(0:(k-1))[-index_use])
}
}
result = list(Type = Type,
FDR_final = FDR_final,
FDR_real = FDR_real,
power = power,
T_x = T_x,
test_stat = test_stat,
ct_final_all = ct_final_all)
}
return(result)
}
G <- 100
k_real <- 4
p_k_real <- c(0.7, 0.1, 0.1, 0.1)
dd = rep(c(0:(k_real-1)), p_k_real * G)
result <- MAP_test(est_result = est_result, Type = c(1:5), dd = dd, nn = 3000)
aaa1 <- proc.time()
aaa1 - aaa
#' @import foreach
#' @import MASS
#' @import mvtnorm
#' @import randtoolbox
#' @import stats
#' @import mclust
#' @import EQL
#' @import matlib
#' @import parallel
#' @md
MAP_test = function(est_result,
dd = NULL,
Type = c(1:6),
nn = 6000){
data_use <- est_result$data_use
result1 <- est_result$result1
n_basis <- data_use$n_basis
# aa <- result1$aa
# aa_use <- aa
# aa_use[which(is.na(log(aa)))] = mean(aa, na.rm = T)
phi <- 1/result1$phi
k <- data_use$k
X1 <- data_use$X1
x <- data_use$x
tttt <- data_use$tttt
G <- dim(data_use$Y1)[1]
Y1 <- data_use$Y1
qmc.grid = halton(nn, 2 * n_basis+1, init = TRUE, normal = FALSE, usetime = FALSE)
eta1_pre = qnorm(qmc.grid[,1])
eta2_pre = t(qnorm(qmc.grid[,2:(n_basis + 1)]))
eta3_pre = t(qnorm(qmc.grid[,(n_basis + 2) : (2 * n_basis + 1)]))
wt = rep(1/nn,nn)
eta2 = x %*% ((eta2_pre ) * sqrt(result1$sigma2))
T_stat_fun = function(sigma2, sigma1_2 , sigma2_2, mu1 , p_k, aa_use){
# phi = rep(1/aa_use, each = n_control + n_treat)
# phi = 1/aa_use
# phi <- 1/1
mm_c_full = list()
for (kk in c(1:k)){
if(kk %in% c(1,2)){
eta1 = rep(0, nn)
}else{
eta1 = eta1_pre * sqrt(sigma1_2) + mu1
}
if(kk %in% c(1,3)){
eta3 = X1 * x %*% (eta3_pre) * 0
}else{
eta3 = X1 * x %*% (eta3_pre * sqrt(sigma2_2))
}
lambda = matrix(0, nrow = nn, ncol = length(tttt))
for(ii in c(1:nn)){
lambda[ii,] = exp(X1 * eta1[ii] + eta2[,ii] + eta3[,ii])
}
f_y_g_eta = function(ii, lambda){
Y = c(t(Y1))
lambda_use = c(replicate(G, lambda[ii,]))
# res = apply(matrix(dnbinom(Y, size = phi, mu = lambda_use, log = T), ncol = G), 2, sum)
res1 = apply(matrix((Y * (log(lambda_use) - log(phi + lambda_use)) +
phi * (log(phi) - log(phi + lambda_use))), ncol = G), 2, sum)
return(res1)
}
res_pre <- foreach(ii = c(1:nn), .combine = "cbind")%do%{
f_y_g_eta(ii, lambda = lambda)
}
res = apply(exp(res_pre), 1, mean)
mm_c_full[[kk]] = res_pre
print(kk)
}
res = matrix(0, nrow = G, ncol = 4)
res_full = matrix(0, nrow = G * length(tttt), ncol = 4)
for(kk in c(1:4)){
res[, kk] = log(apply(exp(mm_c_full[[kk]]), 1, mean)) + log(p_k[kk])
res[res[, kk] == -Inf, kk] = -2000
}
return(res)
}
T_x = T_stat_fun(sigma2 = result1$sigma2,
sigma1_2 = result1$sigma1_2,
sigma2_2 = result1$sigma2_2,
mu1 =  result1$mu1,
p_k = result1$p_k,
aa_use = aa_use)
T_x = (T_x - apply(T_x, 1, max))
FDR_ct = seq(1e-5, 0.6, length.out = 100)
if(is.null(dd)){
FDR <- matrix(0, 100, length(Type))
FDR_final = ct_final_all = matrix(0, length(FDR_ct), length(Type))
test_stat = matrix(0, G, length(Type))
for(ii in c(1:length(Type))){
kk = Type[ii]
print(kk)
if(kk == 1){
index_use = 1 #general DE detection
}else if(kk == 2){
index_use = c(1,2) #mean difference detection
}else if(kk == 3){
index_use = c(1,3) #NPDE detection
}else if(kk == 4){
index_use = c(1,2,4) #PDE with no time-by-treatment
}else if(kk == 5){
index_use = c(1,3,4) # NPDE with only time-by-treatment
}else if(kk == 6){
index_use = c(1,2,3)
}
print(index_use)
res = apply(t(t(exp(T_x)[,index_use])), 1, sum)/apply(exp(T_x), 1, sum)
test_stat[,ii] = res
ct =  seq(min(res),quantile(res)[4], length.out = 100)
for (jj in c(1:length(ct))){
phi_x = (res<=ct[jj])
FDR[jj,ii] = sum(res*phi_x)/sum(phi_x)
}
for(jj in c(1:length(FDR_ct))){
ct_final = max(ct[which(FDR[,ii] == max(FDR[which (FDR[,ii]<=FDR_ct[jj]), ii]))] )
ct_final_all[jj, ii] = ct_final
phi_x = (res<=ct_final)
FDR_final[jj, ii] = sum(res*phi_x)/sum(phi_x)
}
}
result = list(Type = Type,
FDR_final = FDR_final,
T_x = T_x,
test_stat = test_stat,
ct_final_all = ct_final_all)
}else{
FDR = matrix(0, 100, length(Type))
FDR_final = FDR_real = power = ct_final_all = matrix(0, length(FDR_ct), length(Type))
test_stat = matrix(0, G, length(Type))
for(ii in c(1:length(Type))){
kk = Type[ii]
print(kk)
if(kk == 1){
index_use = 1 #general DE detection
}else if(kk == 2){
index_use = c(1,2) #mean difference detection
}else if(kk == 3){
index_use = c(1,3) #NPDE detection
}else if(kk == 4){
index_use = c(1,2,4) #PDE with no time-by-treatment
}else if(kk == 5){
index_use = c(1,3,4) # NPDE with only time-by-treatment
}else if(kk == 6){
index_use = c(1,2,3)
}
print(index_use)
res = apply(t(t(exp(T_x)[,index_use])), 1, sum)/apply(exp(T_x), 1, sum)
test_stat[,ii] = res
ct =  seq(min(res),quantile(res)[4], length.out = 100)
for (jj in c(1:length(ct))){
phi_x = (res<=ct[jj])
FDR[jj,ii] = sum(res*phi_x)/sum(phi_x)
}
for(jj in c(1:length(FDR_ct))){
ct_final = max(ct[which(FDR[,ii] == max(FDR[which (FDR[,ii]<FDR_ct[jj]), kk]))] )
ct_final_all[jj, ii] = ct_final
phi_x = (res<ct_final)
FDR_final[jj, ii] = sum(res*phi_x)/sum(phi_x)
FDR_real[jj, ii] = sum(phi_x[which(dd %in% c(index_use-1))])/sum(phi_x)
power[jj, ii] = sum(phi_x[which(dd %in% c(0:(k-1))[-index_use])])/sum(dd %in%  c(0:(k-1))[-index_use])
}
}
result = list(Type = Type,
FDR_final = FDR_final,
FDR_real = FDR_real,
power = power,
T_x = T_x,
test_stat = test_stat,
ct_final_all = ct_final_all)
}
return(result)
}
result
#' @import foreach
#' @import MASS
#' @import mvtnorm
#' @import randtoolbox
#' @import stats
#' @import mclust
#' @import EQL
#' @import matlib
#' @import parallel
#' @md
Summary_MAP = function(test_result,
alpha = 0.05){
result = list()
Type = test_result$Type
for(ii in c(1:length(Type))){
FDR_hat <- test_result$FDR_final[max(which(test_result$FDR_final[,ii] < alpha)),ii]
rej <- which(test_result$test_stat[,ii] < test_result$ct_final_all[
max(which(test_result$FDR_final[,ii] < alpha)),ii])
result[[ii]] = list(Type = Type[ii],
Reject_index = rej,
FDR_hat = FDR_hat)
}
return(result)
}
Summary_MAP(result)
?Proj
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
library(MAPTest)
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
